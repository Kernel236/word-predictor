<div align="center">

# ğŸ”® Word Predictor: N-gram Language Model

[![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)](https://www.r-project.org/)
[![RStudio](https://img.shields.io/badge/RStudio-4285F4?style=for-the-badge&logo=rstudio&logoColor=white)](https://rstudio.com/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Kernel236/word-predictor)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](https://opensource.org/licenses/MIT)
[![R Version](https://img.shields.io/badge/R-%3E%3D4.0-blue.svg?style=flat-square)](https://www.r-project.org/)
[![Project Status](https://img.shields.io/badge/Status-Active%20Development-green.svg?style=flat-square)](https://github.com/Kernel236/word-predictor)
[![Last Updated](https://img.shields.io/badge/Last%20Updated-October%202025-orange.svg?style=flat-square)](https://github.com/Kernel236/word-predictor)


</div>

---

## ğŸ¯ Project Overview

This project implements a **next-word prediction model** based on statistical n-gram analysis. The system analyzes frequency patterns in unigrams, bigrams, and trigrams to build a predictive language model suitable for text completion applications.

## ğŸ—‚ï¸ Repository Structure

```
word-predictor/
â”œâ”€â”€ README.md                          # Main project documentation
â”œâ”€â”€ .gitignore                        # Git ignore rules (includes rsconnect/)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # SwiftKey corpora (git-ignored)
â”‚   â”‚   â”œâ”€â”€ en_US.blogs.txt           # English blogs (~200MB)
â”‚   â”‚   â”œâ”€â”€ en_US.news.txt            # English news (~200MB)
â”‚   â”‚   â”œâ”€â”€ en_US.twitter.txt         # English tweets (~160MB)
â”‚   â”‚   â””â”€â”€ de_DE.* / fi_FI.* / ru_RU.*  # German, Finnish, Russian
â”‚   â””â”€â”€ processed/                    # Optimized model files (git-ignored)
â”‚       â”œâ”€â”€ uni_lookup.rds            # Unigram lookup (52,718 terms)
â”‚       â”œâ”€â”€ bi_pruned.rds             # Bigram model (183,284 pairs)
â”‚       â”œâ”€â”€ tri_pruned.rds            # Trigram model (508,003 triplets)
â”‚       â””â”€â”€ lang_meta.rds             # Model metadata & statistics
â”œâ”€â”€ R/
â”‚   â”œâ”€â”€ eda.R                         # Exploratory data analysis
â”‚   â”œâ”€â”€ build_lang_model.R            # Model construction pipeline
â”‚   â”œâ”€â”€ predict_demo.R                # CLI prediction demo
â”‚   â”œâ”€â”€ run-model&eval.R              # Model evaluation & benchmarking
â”‚   â””â”€â”€ run-interpolation-eval.R      # Interpolated algorithm evaluation
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ eda.Rmd                       # Research report (R Markdown)
â”‚   â””â”€â”€ cache/                        # Computation cache (git-ignored)
â”œâ”€â”€ docs/                             # ğŸ“– GitHub Pages (Live Demo)
â”‚   â”œâ”€â”€ index.html                    # Published EDA report
â”‚   â””â”€â”€ word-predictor-pitch.html     # Capstone presentation
â”œâ”€â”€ presentation/                     # ğŸ“ Academic Presentation
â”‚   â”œâ”€â”€ word-predictor-pitch.Rmd      # 5-slide capstone presentation
â”‚   â”œâ”€â”€ custom-slides.css             # Optimized slide styling
â”‚   â”œâ”€â”€ mock-data.R                   # Presentation data generation
â”‚   â”œâ”€â”€ plot_algorithm_comparison.png # Real benchmark results
â”‚   â”œâ”€â”€ plot_latency_summary_long_long.png # Performance metrics
â”‚   â”œâ”€â”€ ScreenshotClassicbootstraptheme.png # App screenshots
â”‚   â””â”€â”€ ScreenshoyCyberpunktheme.png  # Theme demonstrations
â”œâ”€â”€ results/                          # Performance evaluation data
â”‚   â”œâ”€â”€ plot_accuracy_at_k_*.png      # Accuracy visualizations
â”‚   â”œâ”€â”€ plot_algorithm_comparison.png # Algorithm benchmarks
â”‚   â”œâ”€â”€ plot_latency_summary_*.png    # Performance analysis
â”‚   â””â”€â”€ plot_rank_hit_distribution_*.png # Prediction distributions
â”œâ”€â”€ word-predictor-app/              # ğŸ”® Interactive Shiny Application
â”‚   â”œâ”€â”€ README.md                     # App-specific documentation
â”‚   â”œâ”€â”€ ui.R                          # Dual-theme interface (Classic/Cyberpunk)
â”‚   â”œâ”€â”€ server.R                      # Prediction server logic  
â”‚   â”œâ”€â”€ utils.R                       # Core algorithm functions (path-aware)
â”‚   â”œâ”€â”€ run_app.R                     # Launch script
â”‚   â”œâ”€â”€ .Rprofile                     # Shinyapps.io deployment config
â”‚   â”œâ”€â”€ uni_lookup.rds                # Model files (deployment copies)
â”‚   â”œâ”€â”€ bi_pruned.rds                 # Bigram model (for shinyapps.io)
â”‚   â”œâ”€â”€ tri_pruned.rds                # Trigram model (for shinyapps.io)
â”‚   â””â”€â”€ www/                          # Web assets & visualizations
â”‚       â”œâ”€â”€ custom.css                # Dual-theme styling system
â”‚       â”œâ”€â”€ custom.js                 # Theme toggle & Easter eggs
â”‚       â””â”€â”€ plot_*.png                # Performance graphs (copied)
â””â”€â”€ word-predictor.Rproj             # RStudio project (git-ignored)
```

## ğŸ“– Methodology

### 1ï¸âƒ£ Data Preprocessing
- ğŸ“š **Corpus Loading**: Multi-source English text data (blogs, news, social media)
- ğŸ§¹ **Text Cleaning**: Standardization, tokenization, and quality filtering
- ğŸ¯ **Sampling Strategy**: Stratified 5% sample maintaining source proportions

### 2ï¸âƒ£ N-gram Analysis
- âœ‚ï¸ **Tokenization**: Generation of unigrams, bigrams, and trigrams
- ğŸ“Š **Frequency Calculation**: Statistical analysis of term occurrence patterns
- ğŸ“ˆ **Coverage Analysis**: Vocabulary size requirements for different coverage thresholds

### 3ï¸âƒ£ Statistical Validation
- ğŸ“ **Zipf's Law Verification**: Confirming power-law distributions in natural language
- ğŸ•³ï¸ **Sparsity Assessment**: Understanding vocabulary growth with n-gram order
- âš¡ **Coverage Efficiency**: Determining optimal vocabulary sizes

## ğŸ“Š Key Findings

<div align="center">
| N-gram Type | 50% Coverage | 90% Coverage | Final Model Size |
|-------------|--------------|--------------|------------------|
| ğŸ”¤ **Unigrams** | ~100 terms | ~1,000 terms | 52,718 terms |
| ğŸ”¤ğŸ”¤ **Bigrams** | ~1,000 terms | ~10,000 terms | 183,284 pairs |
| ğŸ”¤ğŸ”¤ğŸ”¤ **Trigrams** | ~10,000+ terms | ~100,000+ terms | 508,003 triplets |

**Total Model**: 744K n-grams | **Compressed Size**: ~12MB

</div>

## ğŸ”® Interactive Application

The project culminates in a **dual-theme Shiny application** with advanced prediction algorithms and interactive features:

### ğŸš€ Live Demo Features
- ğŸ¯ **Real-time Predictions**: Instant word suggestions as you type
- ğŸ§  **Dual Algorithm Modes**: Stupid Backoff vs. Interpolated+IDF
- ğŸ“Š **Performance Metrics**: Live timing and accuracy statistics
- ğŸ¨ **Dual Theme System**: Classic Bootstrap + Cyberpunk mode with smooth transitions
- âš™ï¸ **Tunable Parameters**: Alpha penalties, lambda weights, and more
- ğŸ® **Easter Eggs**: Hidden Konami code for special effects
- ğŸ“± **Responsive Design**: Works on desktop and mobile devices

### ğŸ¨ Theme Features
| Theme | Style | Features |
|-------|-------|----------|
| **Classic** | Professional Bootstrap | Clean, accessible, business-ready |
| **Cyberpunk** | Neon + Dark | Futuristic aesthetics, glow effects, animations |
| **Rainbow Mode** | Special Effect | 6-second rainbow animation (Easter egg) |

### ğŸ“ˆ Performance Metrics
| Metric | Stupid Backoff | Interpolated+IDF |
|--------|---------------|------------------|
| **Average Latency** | ~30ms | ~45ms |
| **Memory Usage** | 12MB | 12MB |
| **Accuracy Mode** | Fast & Efficient | Research-grade |

> ğŸ“‹ **Full app documentation**: [word-redictor-app/README.md](word-redictor-app/README.md)

## ğŸ“ Academic Presentation

The project includes a **professional 5-slide presentation** suitable for capstone project submissions and academic conferences:

### ğŸ“‘ Presentation Structure
1. **Project Overview** - Problem statement and methodology
2. **N-gram Language Model** - Technical approach and algorithms  
3. **Performance Analysis** - Real benchmark results and timing data
4. **Interactive Demo** - Application features and screenshots
5. **Custom Rcaptext Package** - Technical contributions and GitHub link

### ğŸŒ Live Presentation
- **Location**: [`presentation/word-predictor-pitch.Rmd`](presentation/word-predictor-pitch.Rmd)
- **Online Version**: [GitHub Pages Presentation](https://kernel236.github.io/word-predictor/word-predictor-pitch.html)
- **Format**: ioslides with custom CSS for professional appearance
- **Features**: Real screenshots, performance graphs, and interactive elements

### ğŸ“Š Presentation Assets
- **Real Screenshots**: Both Classic and Cyberpunk themes
- **Performance Graphs**: Actual benchmark results from model evaluation
- **Model Statistics**: N-gram distribution and efficiency metrics
- **GitHub Integration**: Direct links to source code and documentation

## ğŸ”„ Project Workflow

### Phase 1: Data Exploration âœ…
- **Script**: `R/eda.R`
- **Report**: `reports/eda.Rmd` â†’ `docs/index.html`
- **Purpose**: Statistical analysis, Zipf's law validation, coverage optimization
- **Output**: [ğŸ“Š EDA Report](https://kernel236.github.io/word-predictor/)

### Phase 2: Model Building âœ…
- **Script**: `R/build_lang_model.R`
- **Output**: Optimized n-gram lookup tables (744K total terms)
- **Features**: Frequency pruning, back-off structure, memory optimization
- **Size**: ~12MB compressed model

### Phase 3: Algorithm Development âœ…
- **Scripts**: `R/predict_demo.R`, `R/run-model&eval.R`
- **Algorithms**: Stupid Backoff + Interpolated IDF
- **Performance**: <50ms prediction latency, research-grade accuracy
- **Evaluation**: Comprehensive benchmarking with visualizations

### Phase 4: Interactive Application âœ…
- **Location**: `word-predictor-app/`
- **Features**: Dual-theme system, dual algorithm modes, real-time metrics
- **Deployment**: Local development + shinyapps.io production ready
- **Tech Stack**: Shiny + custom CSS/JS + Rcaptext engine

### Phase 5: Academic Presentation âœ…
- **Location**: `presentation/word-predictor-pitch.Rmd`
- **Format**: Professional 5-slide ioslides presentation
- **Content**: Real data, screenshots, performance benchmarks
- **Publishing**: GitHub Pages integration for online access

## ğŸš€ Quick Start

### Prerequisites
```bash
# R version 4.0+ required
R --version
```

### Installation
```bash
# Clone the repository
git clone https://github.com/Kernel236/word-predictor.git
cd word-predictor

# Open RStudio project
open word-predictor.Rproj
```

### Run Complete Pipeline
```r
# 1. Exploratory Data Analysis
source("R/eda.R")

# 2. Build optimized language model
source("R/build_lang_model.R")

# 3. Test CLI prediction demo
source("R/predict_demo.R")

# 4. Run evaluation benchmarks
source("R/run-model&eval.R")

# 5. Launch interactive app
setwd("word-predictor-app")
source("run_app.R")  # Opens at http://localhost:8080

# 6. Generate academic presentation
setwd("../presentation")
rmarkdown::render("word-predictor-pitch.Rmd")
```

### Quick App Launch
```bash
# Navigate to app directory
cd word-predictor-app/

# Launch with default settings
Rscript run_app.R

# Or with custom port
Rscript run_app.R 3838
```

### Quick Presentation Build
```bash
# Navigate to presentation directory
cd presentation/

# Render presentation to HTML
Rscript -e "rmarkdown::render('word-predictor-pitch.Rmd')"

# Open in browser (Linux/Mac)
open word-predictor-pitch.html
```

## âš™ï¸ Technical Dependencies

### ğŸ“¦ R Packages
```r
# Core dependencies
library(Rcaptext)  # ğŸ› ï¸ Custom text processing and n-gram analysis
library(dplyr)     # ğŸ“Š Data manipulation and transformation  
library(tidyr)     # ğŸ”„ Data reshaping and organization
library(ggplot2)   # ğŸ“ˆ Statistical visualization
library(knitr)     # ğŸ“– Report generation
```

### ğŸ’» System Requirements
- ğŸ–¥ï¸ **RAM**: Minimum 1GB available for processing
- ğŸ“Š **R Version**: 4.0+ recommended
- ğŸ“š **Data**: English US text corpora (included in raw data)
- ğŸ’¾ **Storage**: ~500MB for processed frequency tables
- ğŸŒ **Deployment**: Model files duplicated in app/ for shinyapps.io compatibility

## ï¿½ Rcaptext Package: Custom Text Processing Engine

This project is powered by **Rcaptext**, a specialized R package developed specifically for text processing and n-gram analysis. The package provides a suite of functions tailored for natural language processing tasks of this project.

### ğŸŒŸ Key Features (so far...)

- ğŸ“š **`load_corpus()`** - Efficient multi-file corpus loading with automatic source tagging
- ğŸ§¹ **`clean_text()`** - Advanced text preprocessing with configurable cleaning rules
- ğŸ² **`sample_corpus()`** - Stratified sampling maintaining source proportions
- âœ‚ï¸ **`tokenize_unigrams()`**, **`tokenize_bigrams()`**, **`tokenize_trigrams()`** - Optimized n-gram tokenization
- ğŸ“Š **`freq_unigrams()`**, **`freq_bigrams()`**, **`freq_trigrams()`** - Statistical frequency analysis
- ğŸ“ˆ **`coverage_from_freq()`** - Coverage analysis at specified thresholds
- ğŸ¨ **`plot_top_terms()`**, **`plot_rank_frequency()`**, **`plot_cumulative_coverage()`** - Rich visualization functions

### ğŸ“¦ Installation & Usage

```r
# Install development version
devtools::install_github("Kernel236/Rcaptext")

# Load the package
library(Rcaptext)

# Example workflow
corpus <- load_corpus("en_US", base_dir = "data/raw")
clean_corpus <- clean_text(corpus$text)
sample_data <- sample_corpus(corpus, prop = 0.05)
```

> ğŸ”¬ **Development Status**: Rcaptext is actively developed alongside this project, with new features and optimizations added based on real-world text processing needs.

## ï¿½ğŸ“‹ Advanced Usage

### ğŸ”¬ Running the Analysis
```r
# Load the project and run full analysis
source("R/eda.R")

# Generate EDA report (uses caching for improved performance)
rmarkdown::render("reports/eda.Rmd")

# Clear cache if needed (for fresh run)
knitr::clean_cache("reports/eda.Rmd")
```

> ğŸ’¡ **Performance Tip**: The R Markdown report uses intelligent caching to optimize knitting performance.
> 
> - â±ï¸ **First run**: Full processing time (may take several minutes)  
> - âš¡ **Subsequent runs**: Much faster execution using cached results
> - ğŸ“ **Cache location**: `reports/cache/` directory (ignored by git)

### ğŸ“Š Using Processed Data
```r
# Load pre-computed frequency tables
freq_uni <- readRDS("data/processed/freq_uni_en_top100k.rds")
freq_bi  <- readRDS("data/processed/freq_bi_top100k.rds")
freq_tri <- readRDS("data/processed/freq_tri_top100k.rds")
```

## ğŸš€ Performance & Optimization

### ğŸ¯ Model Performance
Based on comprehensive evaluation with `R/run-model&eval.R`:

- **Prediction Speed**: <50ms average latency
- **Model Size**: 744K n-grams compressed to ~12MB  
- **Memory Efficiency**: Optimized lookup structures
- **Accuracy**: Research-grade precision with proper back-off

### ğŸ“Š Benchmark Results
Performance data available in `results/` directory:

- ï¿½ **Accuracy at K**: Hit rates for top-1, top-3, top-5 predictions
- â±ï¸ **Latency Analysis**: Response time distributions and percentiles
- ğŸ¯ **Rank Distribution**: Where correct predictions typically appear
- ğŸ“‹ **Detailed CSVs**: `timing_summary_*.csv`, `hit_breakdown_*.csv`

### ğŸ’¾ Technical Optimizations
- ï¿½ **Smart Caching**: Knitr-based computation caching for development
- ï¿½ **Frequency Pruning**: Removes low-frequency n-grams below thresholds
- ğŸ“¦ **Compressed Storage**: RDS serialization for efficient I/O
- ğŸ§  **Memory Management**: Strategic sampling and garbage collection


## ğŸ¤ Contributing

Contributions are welcome! Please ensure all code follows the established style conventions and includes appropriate documentation.

### ğŸ’¡ How to Contribute
1. ğŸ´ Fork the repository
2. ğŸŒŸ Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push to the branch (`git push origin feature/AmazingFeature`)
5. ğŸ”„ Open a Pull Request

## ğŸ“„ License

This project is developed for educational and research purposes. Please respect the licensing terms of the original corpora datasets.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

<div align="center">

### ğŸ‘¨â€ğŸ’» Author

**Kernel236**

[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Kernel236)

---

*Last Updated: October 29, 2025 | Project Status: ğŸŸ¢ Complete & Deployed*

</div>